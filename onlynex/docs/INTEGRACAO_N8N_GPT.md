# Integra√ß√£o n8n + ChatGPT para Chat das Modelos

## Vis√£o Geral

Esta documenta√ß√£o explica como integrar o webhook do n8n conectado ao ChatGPT para responder automaticamente no chat de cada modelo do OnlyNex.

## Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   OnlyNex App   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    n8n Webhook  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    ChatGPT API  ‚îÇ
‚îÇ   (Frontend)    ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   (Middleware)  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ    (OpenAI)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ
        ‚îÇ                       ‚îÇ
        ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Firebase     ‚îÇ     ‚îÇ  Personalidade  ‚îÇ
‚îÇ   (Modelo ID)   ‚îÇ     ‚îÇ   por Modelo    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Fluxo de Dados

1. **Usu√°rio envia mensagem** no chat da modelo
2. **Frontend envia request** para o webhook do n8n com:
   - `modelId`: ID do documento da modelo no Firestore (obrigat√≥rio)
   - `modelName`: Nome da modelo (obrigat√≥rio)
   - `message`: Mensagem do usu√°rio (obrigat√≥rio)
   - `userId`: Email do usu√°rio autenticado no Firebase Auth (obrigat√≥rio)
   - `userName`: Nome de exibi√ß√£o do usu√°rio
   - `history`: Hist√≥rico das √∫ltimas 10 mensagens
   - `timestamp`: Data/hora da mensagem
3. **n8n recebe** e processa a request
4. **n8n consulta GPT** com contexto personalizado da modelo
5. **GPT responde** com a "voz" da modelo
6. **n8n retorna** a resposta para o frontend
7. **Frontend exibe** a mensagem no chat

> **Importante**: O `userId` √© o email do usu√°rio autenticado via Firebase Authentication. Isso permite identificar cada usu√°rio de forma √∫nica e manter hist√≥rico de conversas.

---

## Configura√ß√£o no n8n

### 1. Criar Workflow no n8n

1. Acesse seu n8n (self-hosted ou cloud)
2. Crie um novo workflow
3. Adicione os seguintes n√≥s:

### 2. N√≥: Webhook (Trigger)

```json
{
  "node": "Webhook",
  "settings": {
    "httpMethod": "POST",
    "path": "onlynex-chat",
    "responseMode": "responseNode",
    "options": {
      "rawBody": false
    }
  }
}
```

**URL do webhook ser√° algo como:**

```
https://seu-n8n.com/webhook/onlynex-chat
```

### 3. N√≥: OpenAI (ChatGPT)

Configure o n√≥ OpenAI com:

```json
{
  "node": "OpenAI",
  "settings": {
    "resource": "chat",
    "operation": "complete",
    "model": "gpt-4o-mini",
    "messages": {
      "values": [
        {
          "role": "system",
          "content": "={{ $json.systemPrompt }}"
        },
        {
          "role": "user",
          "content": "={{ $json.body.message }}"
        }
      ]
    },
    "options": {
      "temperature": 0.8,
      "maxTokens": 150
    }
  }
}
```

### 4. N√≥: Set (Preparar System Prompt)

Antes do OpenAI, adicione um n√≥ "Set" ou "Code" para montar o prompt:

```javascript
// N√≥ Code do n8n
const modelId = $input.first().json.body.modelId;
const modelName = $input.first().json.body.modelName;
const userName = $input.first().json.body.userName || "amor";

const systemPrompt = `Voc√™ √© ${modelName}, uma modelo exclusiva da plataforma OnlyNex.

PERSONALIDADE:
- Voc√™ √© carinhosa, sedutora e atenciosa
- Usa emojis com modera√ß√£o (üíï üòò ü•∞ ‚ú®)
- Responde de forma curta e envolvente (m√°ximo 2-3 frases)
- Flerta de forma leve e divertida
- Sempre trata o usu√°rio pelo nome ou apelidos carinhosos (amor, lindo, bb)

REGRAS:
- NUNCA revele que √© uma IA
- NUNCA quebre o personagem
- Mantenha respostas curtas e naturais
- Se perguntar sobre conte√∫do exclusivo, mencione sua galeria
- Se perguntar sobre chamada privada, diga que pode agendar

CONTEXTO:
- ID da modelo: ${modelId}
- Nome do usu√°rio: ${userName}

Responda como ${modelName} responderia, de forma natural e envolvente.`;

return {
  systemPrompt,
  body: $input.first().json.body,
};
```

### 5. N√≥: Respond to Webhook

```json
{
  "node": "Respond to Webhook",
  "settings": {
    "respondWith": "json",
    "responseBody": {
      "success": true,
      "response": "={{ $json.message.content }}",
      "modelId": "={{ $json.body.modelId }}"
    }
  }
}
```

---

## Configura√ß√£o no Firebase (Opcional)

Se quiser personalizar ainda mais cada modelo, adicione campos no documento:

```javascript
// Documento da modelo no Firestore
{
  id: "abc123",
  name: "Isabella Santos",
  // ... outros campos ...

  // Campos para IA (opcional)
  aiPersonality: {
    tone: "carinhosa e sedutora",
    interests: ["moda", "viagens", "fitness"],
    catchphrases: ["amor", "lindo", "bb"],
    age: 24,
    location: "Rio de Janeiro"
  }
}
```

---

## Configura√ß√£o no Frontend (OnlyNex)

### 1. Arquivo de configura√ß√£o do webhook

Crie/edite o arquivo `.env`:

```env
# Webhook do n8n
VITE_N8N_WEBHOOK_URL=https://seu-n8n.com/webhook/onlynex-chat

# Fallback para respostas locais (caso webhook falhe)
VITE_USE_LOCAL_FALLBACK=true
```

### 2. Servi√ßo de Chat com IA

O arquivo `src/services/chatService.js` foi criado para gerenciar as chamadas:

```javascript
// Importar no Chat.jsx
import { sendMessageToAI } from "../services/chatService";

// Usar no handleSend
const response = await sendMessageToAI({
  modelId: model.id,
  modelName: model.name,
  message: userMessage.text,
  userName: username,
});
```

---

## Testando a Integra√ß√£o

### 1. Teste o webhook diretamente

```bash
curl -X POST https://seu-n8n.com/webhook/onlynex-chat \
  -H "Content-Type: application/json" \
  -d '{
    "modelId": "abc123",
    "modelName": "Isabella Santos",
    "message": "Oi, tudo bem?",
    "userId": "usuario@email.com",
    "userName": "Jo√£o",
    "history": [],
    "timestamp": "2024-12-21T15:30:00.000Z"
  }'
```

**Resposta esperada:**

```json
{
  "success": true,
  "response": "Oii Jo√£o! üíï Tudo √≥timo, ainda mais agora falando com voc√™! Como foi seu dia?",
  "modelId": "abc123"
}
```

### Par√¢metros do Request

| Par√¢metro   | Tipo   | Obrigat√≥rio | Descri√ß√£o                              |
| ----------- | ------ | ----------- | -------------------------------------- |
| `modelId`   | string | ‚úÖ Sim      | ID do documento da modelo no Firestore |
| `modelName` | string | ‚úÖ Sim      | Nome da modelo                         |
| `message`   | string | ‚úÖ Sim      | Mensagem do usu√°rio                    |
| `userId`    | string | ‚úÖ Sim      | Email do usu√°rio (Firebase Auth)       |
| `userName`  | string | N√£o         | Nome de exibi√ß√£o do usu√°rio            |
| `history`   | array  | N√£o         | √öltimas 10 mensagens da conversa       |
| `timestamp` | string | N√£o         | Data/hora ISO da mensagem              |

### 2. Teste no app

1. Acesse o chat de uma modelo
2. Envie uma mensagem
3. Verifique se a resposta vem do GPT

---

## Personaliza√ß√£o Avan√ßada

### Mem√≥ria de Conversa

Para manter contexto da conversa, voc√™ pode:

1. **Armazenar no Firestore:**

   - Crie uma subcole√ß√£o `chats/{modelId}/messages`
   - Envie os √∫ltimos N mensagens para o GPT

2. **No n8n:**
   - Use um n√≥ de banco de dados para buscar hist√≥rico
   - Inclua no array de mensagens do GPT

### Exemplo com hist√≥rico:

```javascript
// No n√≥ Code do n8n
const messages = [
  { role: "system", content: systemPrompt },
  // Hist√≥rico (√∫ltimas 5 mensagens)
  ...history.map((msg) => ({
    role: msg.sender === "user" ? "user" : "assistant",
    content: msg.text,
  })),
  // Mensagem atual
  { role: "user", content: currentMessage },
];
```

---

## Custos e Limites

### OpenAI Pricing (GPT-4o-mini)

- Input: $0.15 / 1M tokens
- Output: $0.60 / 1M tokens

### Estimativa por mensagem

- ~50 tokens input + ~50 tokens output = ~100 tokens
- Custo: ~$0.0001 por mensagem
- 10.000 mensagens = ~$1.00

### Rate Limits

- Configure limites no n8n para evitar abusos
- Implemente debounce no frontend (j√° feito)

---

## Troubleshooting

### Webhook n√£o responde

1. Verifique se o workflow est√° ativo no n8n
2. Confira a URL do webhook
3. Teste com curl primeiro

### Respostas gen√©ricas demais

1. Ajuste o system prompt
2. Aumente a temperature (0.7-0.9)
3. Adicione mais contexto sobre a modelo

### Respostas muito longas

1. Reduza maxTokens (100-150)
2. Adicione "Responda em 1-2 frases" no prompt

### Erro de CORS

1. Configure headers no n8n:

```json
{
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Methods": "POST, OPTIONS",
  "Access-Control-Allow-Headers": "Content-Type"
}
```

---

## Pr√≥ximos Passos

1. [ ] Configure o webhook no n8n
2. [ ] Adicione a URL no `.env`
3. [ ] Teste a integra√ß√£o
4. [ ] Personalize os prompts por modelo
5. [ ] Implemente hist√≥rico de conversa (opcional)
6. [ ] Configure limites de uso (opcional)

---

## Suporte

D√∫vidas? Entre em contato ou abra uma issue no reposit√≥rio.
